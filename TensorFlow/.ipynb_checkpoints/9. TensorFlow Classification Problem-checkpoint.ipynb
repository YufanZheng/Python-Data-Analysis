{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MINST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data\n",
    "- See how many images we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data contains 55000 images.\n",
      "Test  data contains 10000 images.\n",
      "Eval  data contains 5000 images.\n"
     ]
    }
   ],
   "source": [
    "print( \"Train data contains {} images.\".format(mnist.train.num_examples) )\n",
    "print( \"Test  data contains {} images.\".format(mnist.test.num_examples) )\n",
    "print( \"Eval  data contains {} images.\".format(mnist.validation.num_examples) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- See some picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR0AAADxCAYAAAD2m2M2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ef9ff28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.array( mnist.train.next_batch(1)[0] ).reshape(28, 28)\n",
    "plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\", origin=\"lower\")\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define add layer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_dim, out_dim, activation_function=None):\n",
    "    Weight = tf.Variable( tf.random_normal( shape=(in_dim, out_dim)), dtype=tf.float32, name=\"W\")\n",
    "    biases = tf.Variable( tf.zeros( shape=(out_dim) ) + 0.1,          dtype=tf.float32, name=\"b\")\n",
    "    Wx_plus_b = tf.matmul(inputs, Weight) + biases\n",
    "    if activation_function == None:\n",
    "        output = Wx_plus_b\n",
    "    else:\n",
    "        output = activation_function(Wx_plus_b)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define placeholder for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = tf.placeholder(tf.float32, [None, 784]) # 28x28\n",
    "ys = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = add_layer(xs, 784, 10, activation_function=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), reduction_indices=[1])) # loss\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1304\n",
      "0.6606\n",
      "0.7506\n",
      "0.7827\n",
      "0.802\n",
      "0.8192\n",
      "0.8314\n",
      "0.8396\n",
      "0.8454\n",
      "0.8534\n",
      "0.8542\n",
      "0.8509\n",
      "0.8616\n",
      "0.861\n",
      "0.8684\n",
      "0.8723\n",
      "0.8737\n",
      "0.873\n",
      "0.8746\n",
      "0.8735\n",
      "0.8786\n",
      "0.8789\n",
      "0.8806\n",
      "0.8821\n",
      "0.8825\n",
      "0.8815\n",
      "0.8843\n",
      "0.8865\n",
      "0.8857\n",
      "0.8862\n",
      "0.89\n",
      "0.8905\n",
      "0.8904\n",
      "0.8903\n",
      "0.8912\n",
      "0.8926\n",
      "0.8915\n",
      "0.8931\n",
      "0.8948\n",
      "0.8916\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(2000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "        if i % 50 == 0:\n",
    "            print(compute_accuracy(\n",
    "                mnist.test.images, mnist.test.labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
