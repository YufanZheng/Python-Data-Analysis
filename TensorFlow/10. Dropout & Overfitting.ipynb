{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Dropout Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data\n",
    "X = X / X.max()\n",
    "y = digits.target\n",
    "y = LabelBinarizer().fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add layer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size, keep_prob, activation_function=None):\n",
    "    Weights = tf.Variable(tf.random_normal(shape=[in_size,out_size], dtype=tf.float32))\n",
    "    biases  = tf.Variable(tf.zeros(shape=[1, out_size], dtype=tf.float32)+0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n",
    "    \n",
    "    # Dropout here\n",
    "    Wx_plus_b = tf.nn.dropout(Wx_plus_b, keep_prob)\n",
    "    \n",
    "    if activation_function is None:\n",
    "        return Wx_plus_b\n",
    "    else:\n",
    "        return activation_function(Wx_plus_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = tf.placeholder(shape=[None, 64], dtype=tf.float32, name='data')\n",
    "ys = tf.placeholder(shape=[None, 10], dtype=tf.float32, name='target')\n",
    "\n",
    "# Dropout keep prob\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "hidden_layer = add_layer(xs,           64, 32, keep_prob, tf.nn.tanh)\n",
    "prediction   = add_layer(hidden_layer, 32, 10, keep_prob, tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys*tf.log(prediction), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.6).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 ------------\n",
      "Train loss: 5.20166\n",
      "Test  loss: 5.16893\n",
      "Step 50 ------------\n",
      "Train loss: 0.608804\n",
      "Test  loss: 0.593022\n",
      "Step 100 ------------\n",
      "Train loss: 0.375994\n",
      "Test  loss: 0.385483\n",
      "Step 150 ------------\n",
      "Train loss: 0.28977\n",
      "Test  loss: 0.303901\n",
      "Step 200 ------------\n",
      "Train loss: 0.242276\n",
      "Test  loss: 0.260062\n",
      "Step 250 ------------\n",
      "Train loss: 0.207227\n",
      "Test  loss: 0.228767\n",
      "Step 300 ------------\n",
      "Train loss: 0.178415\n",
      "Test  loss: 0.205939\n",
      "Step 350 ------------\n",
      "Train loss: 0.159978\n",
      "Test  loss: 0.192223\n",
      "Step 400 ------------\n",
      "Train loss: 0.141427\n",
      "Test  loss: 0.175726\n",
      "Step 450 ------------\n",
      "Train loss: 0.130555\n",
      "Test  loss: 0.165017\n",
      "--------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACoRJREFUeJzt3e+r1vUdx/HXa6diazUF10Z4ZHojhBhMI4RwZDMatiJ3\nYzcUChcDbxUdNgjbrfwH4uzGCMTMIJdslhDRikZJC7aW2nFLjw0nZ3jMZjFE68bEeu/G+TosHNf3\neH2+P643zwdI58fF+byv6un3e13nur4fR4QA5PSVrgcA0BwCBxIjcCAxAgcSI3AgMQIHEiNwIDEC\nBxIjcCCxq5r4obZ5eVwBY2Njra21ZMmS1tZatGhRa2t98MEHra0lSadOnWptrYjwoNu4iZeqEngZ\nCxcubG2tycnJ1tbatGlTa2tt3bq1tbUk6fHHH29trTqBc4oOJEbgQGIEDiRG4EBiBA4kRuBAYgQO\nJEbgQGK1Are9zvb7to/Z3tL0UADKGBi47TFJv5Z0t6SbJW20fXPTgwEYXp0j+CpJxyLieEScl7Rb\n0vpmxwJQQp3AF0s6ccnns9XXAPRcsXeT2d4saXOpnwdgeHUCPynp0vcSjldf+4KI2CZpm8S7yYC+\nqHOK/o6km2wvs32NpA2SXmx2LAAlDDyCR8QF2w9JelXSmKQdEXG48ckADK3WY/CIeFnSyw3PAqAw\nXskGJEbgQGIEDiRG4EBiBA4kRuBAYgQOJEbgQGKNbF3UpjZ3/5iYmGhtrbbXW7BgQWtrtanN/z/6\niCM4kBiBA4kROJAYgQOJETiQGIEDiRE4kBiBA4kROJBYnZ1Ndtg+bfu9NgYCUE6dI/hOSesangNA\nAwYGHhFvSvp3C7MAKIzH4EBibF0EJFYscLYuAvqHU3QgsTq/JntO0p8kLbc9a/tnzY8FoIQ6e5Nt\nbGMQAOVxig4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kRuBAYiO/ddHk5GRra23atKm1tSTp0KFDra01\nMzPT2lrr169vba0zZ860tlYfcQQHEiNwIDECBxIjcCAxAgcSI3AgMQIHEiNwIDECBxIjcCCxOhdd\nXGL7DdtHbB+2/UgbgwEYXp3Xol+Q9IuIOGj7ekkHbL8WEUcang3AkOrsTXYqIg5WH5+TNC1pcdOD\nARjevN5NZnuppJWS3r7M99i6COiZ2oHbvk7S85ImIuLsl7/P1kVA/9R6Ft321ZqLe1dEvNDsSABK\nqfMsuiU9JWk6Ip5ofiQApdQ5gq+W9ICktbanqj8/anguAAXU2ZvsLUluYRYAhfFKNiAxAgcSI3Ag\nMQIHEiNwIDECBxIjcCAxAgcSG/m9ySYmJlpba+fOna2tJUn79u1rba2271tb2vx32EccwYHECBxI\njMCBxAgcSIzAgcQIHEiMwIHECBxIjMCBxOpcdPGrtv9i+1C1ddHWNgYDMLw6L1X9j6S1EfFJdfnk\nt2z/PiL+3PBsAIZU56KLIemT6tOrqz9sbACMgLobH4zZnpJ0WtJrEXHZrYts77e9v/SQAK5MrcAj\n4rOIWCFpXNIq29+9zG22RcStEXFr6SEBXJl5PYseEWckvSFpXTPjACipzrPoN9heWH38NUl3STra\n9GAAhlfnWfQbJT1je0xzfyH8NiJeanYsACXUeRb9r5rbExzAiOGVbEBiBA4kRuBAYgQOJEbgQGIE\nDiRG4EBiBA4k5rl3gxb+oTZvJx0xbW7xs2bNmtbWst3aWm2LiIF3jiM4kBiBA4kROJAYgQOJETiQ\nGIEDiRE4kBiBA4kROJBY7cCra6O/a5vrsQEjYj5H8EckTTc1CIDy6u5sMi7pHknbmx0HQEl1j+CT\nkh6V9HmDswAorM7GB/dKOh0RBwbcjr3JgJ6pcwRfLek+2zOSdktaa/vZL9+IvcmA/hkYeEQ8FhHj\nEbFU0gZJr0fE/Y1PBmBo/B4cSKzO3mT/ExH7JO1rZBIAxXEEBxIjcCAxAgcSI3AgMQIHEiNwIDEC\nBxIjcCAxAgcSI3AgMQIHEiNwIDECBxIjcCAxAgcSI3AgMQIHEiNwILFal2yqrqh6TtJnki5w5VRg\nNMznmmw/iIiPG5sEQHGcogOJ1Q08JP3B9gHbm5scCEA5dU/Rvx8RJ21/S9Jrto9GxJuX3qAKn/iB\nHql1BI+Ik9U/T0vaK2nVZW7D1kVAz9TZfPDrtq+/+LGkH0p6r+nBAAyvzin6tyXttX3x9r+JiFca\nnQpAEQMDj4jjkr7XwiwACuPXZEBiBA4kRuBAYgQOJEbgQGIEDiRG4EBiBA4kNp/3gwMjZ8WKFa2u\nNzU11ep6g3AEBxIjcCAxAgcSI3AgMQIHEiNwIDECBxIjcCAxAgcSqxW47YW299g+anva9m1NDwZg\neHVfqvorSa9ExE9sXyPp2gZnAlDIwMBtL5B0u6SfSlJEnJd0vtmxAJRQ5xR9maSPJD1t+13b26vr\nowPouTqBXyXpFklPRsRKSZ9K2vLlG9nebHu/7f2FZwRwheoEPitpNiLerj7fo7ngv4Cti4D+GRh4\nRHwo6YTt5dWX7pR0pNGpABRR91n0hyXtqp5BPy7pweZGAlBKrcAjYkoSp97AiOGVbEBiBA4kRuBA\nYgQOJEbgQGIEDiRG4EBiBA4kRuBAYuxNBknSzMxMa2utWbOmtbXuuOOO1taS2JsMQIsIHEiMwIHE\nCBxIjMCBxAgcSIzAgcQIHEiMwIHEBgZue7ntqUv+nLU90cZwAIYz8KWqEfG+pBWSZHtM0klJexue\nC0AB8z1Fv1PSPyLin00MA6Cs+b7ZZIOk5y73DdubJW0eeiIAxdQ+glebHtwn6XeX+z5bFwH9M59T\n9LslHYyIfzU1DICy5hP4Rv2f03MA/VQr8Go/8LskvdDsOABKqrs32aeSFjU8C4DCeCUbkBiBA4kR\nOJAYgQOJETiQGIEDiRE4kBiBA4k5Isr/UPsjSfN9S+k3JX1cfJh+yHrfuF/d+U5E3DDoRo0EfiVs\n78/6TrSs94371X+cogOJETiQWJ8C39b1AA3Ket+4Xz3Xm8fgAMrr0xEcQGG9CNz2Otvv2z5me0vX\n85Rge4ntN2wfsX3Y9iNdz1SS7THb79p+qetZSrK90PYe20dtT9u+reuZhtH5KXp1rfW/a+6KMbOS\n3pG0MSKOdDrYkGzfKOnGiDho+3pJByT9eNTv10W2fy7pVknfiIh7u56nFNvPSPpjRGyvLjR6bUSc\n6XquK9WHI/gqScci4nhEnJe0W9L6jmcaWkScioiD1cfnJE1LWtztVGXYHpd0j6TtXc9Sku0Fkm6X\n9JQkRcT5UY5b6kfgiyWduOTzWSUJ4SLbSyWtlPR2t5MUMynpUUmfdz1IYcskfSTp6erhx/bqeoQj\nqw+Bp2b7OknPS5qIiLNdzzMs2/dKOh0RB7qepQFXSbpF0pMRsVLSp5JG+jmhPgR+UtKSSz4fr742\n8mxfrbm4d0VElivSrpZ0n+0ZzT2cWmv72W5HKmZW0mxEXDzT2qO54EdWHwJ/R9JNtpdVT2pskPRi\nxzMNzbY191huOiKe6HqeUiLisYgYj4ilmvtv9XpE3N/xWEVExIeSTtheXn3pTkkj/aTofPcmKy4i\nLth+SNKrksYk7YiIwx2PVcJqSQ9I+pvtqeprv4yIlzucCYM9LGlXdbA5LunBjucZSue/JgPQnD6c\nogNoCIEDiRE4kBiBA4kROJAYgQOJETiQGIEDif0XqN98jYTy1NUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1183019e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(500):\n",
    "        sess.run(train_step, feed_dict={xs: X_train, ys: y_train, keep_prob: 0.6})\n",
    "        if i % 50 == 0:\n",
    "            print(\"Step\", i, '------------')\n",
    "            print('Train loss:', sess.run(cross_entropy, feed_dict={xs: X_train, ys: y_train, keep_prob: 1} ))\n",
    "            print('Test  loss:', sess.run(cross_entropy, feed_dict={xs: X_test,  ys: y_test , keep_prob: 1} ))\n",
    "            \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    print('--------------------------')\n",
    "    \n",
    "    i = np.random.randint(0, X_train.shape[0])\n",
    "    \n",
    "    plt.imshow(X_train[i].reshape(8,8), cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    print('Prediction:', np.argmax(sess.run(prediction, feed_dict={xs: X_train[i][np.newaxis,:], keep_prob: 1})))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
