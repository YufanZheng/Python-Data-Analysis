{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow RNN Net for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('./MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "training_iters = 100000\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## MNIST dataset 28*28\n",
    "n_inputs = 28 \n",
    "n_steps = 28\n",
    "n_classes = 10\n",
    "n_hidden_units = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(shape=[None, 784], dtype=tf.float32, name='input')\n",
    "y = tf.placeholder(shape=[None, 10],  dtype=tf.float32, name='digit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Weights = {\n",
    "    'in' : tf.Variable(tf.random_normal(shape=[n_inputs, n_hidden_units],  dtype=tf.float32, name='in_Weight')),\n",
    "    'out': tf.Variable(tf.random_normal(shape=[n_hidden_units, n_classes], dtype=tf.float32, name='out_Weight'))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'in' : tf.Variable(tf.constant(0.1, shape=[n_hidden_units]), name='in_bais'),\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[n_classes])     , name='out_bais')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input layer before rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X(num_batches, 28 steps, 28 inputs)\n",
    "# --> X(num_batches*28, 28 inputs)\n",
    "x_reshape = tf.reshape(x, [-1, n_inputs])\n",
    "# --> X_in(num_batches*128, 28 inputs)\n",
    "x_in = tf.matmul(x_reshape, Weights['in']) + biases['in']\n",
    "# --> X_in(num_batches, 28 steps, 128 inputs)\n",
    "x_in = tf.reshape(x_in, [-1, n_steps, n_hidden_units])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(\n",
    "    num_units=n_hidden_units, \n",
    "    forget_bias=1.0, \n",
    "    state_is_tuple=True\n",
    ")\n",
    "# state_is_tuple = True\n",
    "# LSTM state is divided into two parts (c_state, m_state)\n",
    "initial_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "# Compute rnn\n",
    "outputs, states = tf.nn.dynamic_rnn(\n",
    "    cell=lstm_cell, \n",
    "    inputs=x_in, \n",
    "    initial_state=initial_state\n",
    ")\n",
    "\n",
    "rnn_output = states[1]\n",
    "\n",
    "# or\n",
    "# transpose : (batch_size, steps, n_hidden_units) -> (batch_size, n_hidden_units, steps)\n",
    "# unpack    : outputs as list [(batch outputs)...] * steps\n",
    "\n",
    "# outputs = tf.unstack(tf.transpose(outputs, [1,0,2]))\n",
    "# rnn_output = outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = tf.matmul(rnn_output, Weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=prediction)\n",
    "train = tf.train.AdamOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.metrics.accuracy(labels=tf.argmax(y, axis=1), predictions=tf.argmax(prediction, axis=1))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.101562\n",
      "0.171875\n",
      "0.239583\n",
      "0.28125\n",
      "0.323438\n",
      "0.363281\n",
      "0.405134\n",
      "0.435547\n",
      "0.459201\n",
      "0.478906\n",
      "0.50142\n",
      "0.51888\n",
      "0.536659\n",
      "0.545759\n",
      "0.558333\n",
      "0.569824\n",
      "0.58318\n",
      "0.59592\n",
      "0.60773\n",
      "0.616797\n",
      "0.622396\n",
      "0.630327\n",
      "0.637568\n",
      "0.644857\n",
      "0.650937\n",
      "0.655649\n",
      "0.662616\n",
      "0.667969\n",
      "0.672953\n",
      "0.677083\n",
      "0.681956\n",
      "0.6875\n",
      "0.691761\n",
      "0.695312\n",
      "0.699554\n",
      "0.703342\n",
      "0.707348\n",
      "0.710938\n",
      "0.715545\n",
      "0.718359\n",
      "0.72218\n",
      "0.724702\n",
      "0.727471\n",
      "0.731534\n",
      "0.736111\n",
      "0.738961\n",
      "0.742354\n",
      "0.745931\n",
      "0.748565\n",
      "0.750156\n",
      "0.752451\n",
      "0.754958\n",
      "0.757518\n",
      "0.759983\n",
      "0.763636\n",
      "0.765765\n",
      "0.768092\n",
      "0.770474\n",
      "0.772643\n",
      "0.775391\n",
      "0.777152\n",
      "0.778226\n",
      "0.780506\n",
      "0.782471\n",
      "0.784495\n",
      "0.786222\n",
      "0.78743\n",
      "0.788488\n",
      "0.789742\n",
      "0.791295\n",
      "0.792804\n",
      "0.794705\n",
      "0.796875\n",
      "0.797614\n",
      "0.799375\n",
      "0.800473\n",
      "0.801542\n",
      "0.802885\n",
      "0.804391\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Init step\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    # Train\n",
    "    step=0\n",
    "    while step*batch_size < training_iters:\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train, feed_dict={\n",
    "            x: batch_xs,\n",
    "            y: batch_ys\n",
    "        })\n",
    "        if step%10==0:\n",
    "            batch_xs, batch_ys = mnist.validation.next_batch(batch_size)\n",
    "            print(sess.run(accuracy, feed_dict={\n",
    "                x: batch_xs,\n",
    "                y: batch_ys\n",
    "            }))\n",
    "        step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
