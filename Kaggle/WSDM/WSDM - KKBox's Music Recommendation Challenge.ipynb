{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WSDM - Collaborative Filtering with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the preprocessed data\n",
    "- data: training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----------------+-------------------+---------------+------+\n",
      "| msno|song_id|source_system_tab| source_screen_name|    source_type|target|\n",
      "+-----+-------+-----------------+-------------------+---------------+------+\n",
      "| 9176| 474849|          explore|            Explore|online-playlist|     1|\n",
      "|19273|1425656|       my library|Local playlist more| local-playlist|     1|\n",
      "|19273| 768950|       my library|Local playlist more| local-playlist|     1|\n",
      "|19273| 150624|       my library|Local playlist more| local-playlist|     1|\n",
      "| 9176| 210388|          explore|            Explore|online-playlist|     1|\n",
      "+-----+-------+-----------------+-------------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the zip csv file\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# Load data and have a look\n",
    "df = sqlContext.read \\\n",
    "        .format('com.databricks.spark.csv') \\\n",
    "        .options(header='true', inferschema='true') \\\n",
    "        .load('./process/train.csv.gz')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will only choose three columns for the recommendations\n",
    "- msno: user_id\n",
    "- song_id\n",
    "- target: score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+------+\n",
      "| msno|song_id|target|\n",
      "+-----+-------+------+\n",
      "| 9176| 474849|     1|\n",
      "|19273|1425656|     1|\n",
      "|19273| 768950|     1|\n",
      "|19273| 150624|     1|\n",
      "| 9176| 210388|     1|\n",
      "+-----+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Keep only 3 columns\n",
    "df = df.select(['msno', 'song_id', 'target'])\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's firstly check if the dataset if balanced\n",
    "- From the result, we find that the positive and negative occupy almost the same\n",
    "- So we don't need to rebalance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 0.5035170841614234 \n",
      "Negative: 0.49648291583857657\n"
     ]
    }
   ],
   "source": [
    "total    = df.count()\n",
    "positive = df.filter(df['target']==1).count()\n",
    "negative = df.filter(df['target']==0).count()\n",
    "\n",
    "print(\"Positive: {} \\nNegative: {}\".format(float(positive)/total, float(negative)/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random split the data into train and eval\n",
    "- Train: 0.8\n",
    "- Eval : 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDF, testDF = df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Recommendation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"msno\", itemCol=\"song_id\", ratingCol=\"target\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als.fit(trainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model by computing the RMSE on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.4760644035693233\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate on test dataset\n",
    "predictions = model.transform(testDF)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"target\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
